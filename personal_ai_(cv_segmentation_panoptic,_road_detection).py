# -*- coding: utf-8 -*-
"""Personal: AI (CV: Segmentation Panoptic, Road Detection).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13L2t_3vl95OpfyCsBwtNrjDdD84FWLiw
"""

!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html
!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html
exit(0)

# !git clone https://github.com/facebookresearch/detectron2.git
import cv2
import detectron2
from detectron2 import model_zoo
from detectron2.utils.visualizer import Visualizer
from detectron2.engine import DefaultPredictor
from detectron2.data import MetadataCatalog
from detectron2.config import get_cfg

video = cv2.VideoCapture("//content//drive//MyDrive//Coding//Personal Projects//1: Artificial Intelligence//Resources//RoadDetection.mp4")
videoWidth = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
videoHeight = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*"MP4V")
output = cv2.VideoWriter("RoadDetection_Segmented.mp4", fourcc, 30.0, (videoWidth, videoHeight))
ret, frame = video.read()
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml")
predictor = DefaultPredictor(cfg)

while (ret):
  predictions, segmentInfo = predictor(frame)["panoptic_seg"]
  v = Visualizer(frame[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale = 1)
  out = v.draw_panoptic_seg_predictions(predictions.to("cpu"), segmentInfo, area_threshold = 0.1)
  output.write(out.get_image()[:,:,::-1])
  ret, frame = video.read()

video.release()
output.release()
cv2.destroyAllWindows()